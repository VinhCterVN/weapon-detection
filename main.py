import time
from collections import defaultdict
from datetime import datetime

import cv2
import pandas as pd
import streamlit as st
import torch
from ultralytics import YOLO

st.set_page_config(
    page_title="Weapon Detection System",
    page_icon="üî´",
    layout="wide",
    initial_sidebar_state="expanded"
)

with open("asset/style.css") as f:
    st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

# Kh·ªüi t·∫°o session state
if 'detection_count' not in st.session_state:
    st.session_state.detection_count = defaultdict(int)
if 'detection_history' not in st.session_state:
    st.session_state.detection_history = []
if 'total_detections' not in st.session_state:
    st.session_state.total_detections = 0
if 'alert_log' not in st.session_state:
    st.session_state.alert_log = []
if 'running' not in st.session_state:
    st.session_state.running = False
if 'tracked_objects' not in st.session_state:
    st.session_state.tracked_objects = {}  # {track_id: {'class': name, 'first_seen': time, 'counted': bool}}
if 'unique_objects' not in st.session_state:
    st.session_state.unique_objects = set()  # Set of counted track_ids


# Load model
@st.cache_resource
def load_model(model_path):
    try:
        yolo_model = YOLO(model_path)
        return yolo_model
    except Exception as e:
        st.error(f"L·ªói khi load model: {e}")
        return None


# Header
st.markdown('<h1 class="main-header">üî´ H·ªÜ TH·ªêNG PH√ÅT HI·ªÜN V≈® KH√ç</h1>', unsafe_allow_html=True)

# Ki·ªÉm tra CUDA
cuda_available = torch.cuda.is_available()
device = 0 if cuda_available else 'cpu'

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u h√¨nh")

    # Hi·ªÉn th·ªã tr·∫°ng th√°i GPU
    if cuda_available:
        st.success(f"‚úÖ GPU kh·∫£ d·ª•ng: {torch.cuda.get_device_name(0)}")
    else:
        st.warning("‚ö†Ô∏è ƒêang s·ª≠ d·ª•ng CPU (kh√¥ng ph√°t hi·ªán GPU)")

    model_path = st.text_input("ƒê∆∞·ªùng d·∫´n model", value="best.pt")
    confidence_threshold = st.slider("Ng∆∞·ª°ng tin c·∫≠y", 0.0, 1.0, 0.5, 0.05)
    camera_index = st.number_input("Camera Index", value=0, min_value=0)

    # C·∫•u h√¨nh video
    st.subheader("üìπ C·∫•u h√¨nh Video")
    resolution = st.selectbox("ƒê·ªô ph√¢n gi·∫£i",
                              ["640x480 (Nhanh)", "1280x720 (Trung b√¨nh)", "1920x1080 (Ch·∫≠m)"],
                              index=0)
    fps_limit = st.slider("Gi·ªõi h·∫°n FPS", 5, 30, 15, 5)

    # C·∫•u h√¨nh tracking
    st.subheader("üéØ C·∫•u h√¨nh Tracking")
    use_tracking = st.checkbox("B·∫≠t tracking (ƒë·∫øm v·∫≠t th·ªÉ duy nh·∫•t)", value=True)
    tracking_persist = st.slider("Th·ªùi gian nh·ªõ v·∫≠t th·ªÉ (gi√¢y)", 1, 10, 3, 1)

    st.divider()

    col1, col2 = st.columns(2)
    with col1:
        if st.button("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu", width="stretch"):
            st.session_state.running = True
    with col2:
        if st.button("‚è∏Ô∏è D·ª´ng", width="stretch"):
            st.session_state.running = False

    if st.button("üîÑ Reset d·ªØ li·ªáu", width="stretch"):
        st.session_state.detection_count = defaultdict(int)
        st.session_state.detection_history = []
        st.session_state.total_detections = 0
        st.session_state.alert_log = []
        st.session_state.tracked_objects = {}
        st.session_state.unique_objects = set()
        st.rerun()

    st.divider()
    st.info(
        "üìå **H∆∞·ªõng d·∫´n:**\n\n1. C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n model\n2. ƒêi·ªÅu ch·ªânh ng∆∞·ª°ng tin c·∫≠y\n3. Nh·∫•n 'B·∫Øt ƒë·∫ßu' ƒë·ªÉ ph√°t hi·ªán")

# Main content
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("üìπ Camera Tr·ª±c Ti·∫øp")
    video_placeholder = st.empty()

with col2:
    st.subheader("üìä Th·ªëng K√™ Theo Th·ªùi Gian Th·ª±c")

    # Metrics
    metric_col1, metric_col2 = st.columns(2)
    total_metric = metric_col1.empty()
    unique_metric = metric_col2.empty()

    # B·∫£ng ƒë·∫øm theo lo·∫°i
    count_table = st.empty()

    # C·∫£nh b√°o
    st.subheader("‚ö†Ô∏è C·∫£nh B√°o")
    alert_placeholder = st.empty()

# B·∫£ng l·ªãch s·ª≠
st.subheader("üìã L·ªãch S·ª≠ Ph√°t Hi·ªán")
history_placeholder = st.empty()

# Ch·∫°y detection
if st.session_state.running:
    model = load_model(model_path)

    if model is not None:
        # Parse resolution
        width, height = map(int, resolution.split('x')[0].split()[0]), \
            map(int, resolution.split('x')[1].split()[0])
        width = int(resolution.split('x')[0])
        height = int(resolution.split('x')[1].split()[0])

        # S·ª≠ d·ª•ng DirectShow backend tr√™n Windows ƒë·ªÉ tr√°nh l·ªói MSMF
        cap = cv2.VideoCapture(camera_index, cv2.CAP_DSHOW)

        # Set c·∫•u h√¨nh
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        cap.set(cv2.CAP_PROP_FPS, fps_limit)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

        if not cap.isOpened():
            st.error("‚ùå Kh√¥ng th·ªÉ m·ªü camera")
            st.session_state.running = False
        else:
            frame_count = 0
            last_process_time = time.time()
            frame_interval = 1.0 / fps_limit

            while st.session_state.running:
                ret, frame = cap.read()
                if not ret:
                    st.warning("‚ö†Ô∏è Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c frame t·ª´ camera. ƒêang th·ª≠ k·∫øt n·ªëi l·∫°i...")
                    cap.release()
                    time.sleep(1)
                    cap = cv2.VideoCapture(camera_index, cv2.CAP_DSHOW)
                    cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
                    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
                    cap.set(cv2.CAP_PROP_FPS, fps_limit)
                    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                    continue

                # Ki·ªÉm tra th·ªùi gian ƒë·ªÉ gi·ªõi h·∫°n FPS
                current_time = time.time()
                if current_time - last_process_time < frame_interval:
                    continue
                last_process_time = current_time

                # Ch·∫°y detection ho·∫∑c tracking
                if use_tracking:
                    # S·ª≠ d·ª•ng track() thay v√¨ __call__() ƒë·ªÉ c√≥ track_id
                    results = model.track(frame, conf=confidence_threshold, device=device,
                                          persist=True, tracker="bytetrack.yaml")
                else:
                    results = model(frame, conf=confidence_threshold, device=device, stream=True)

                detected_objects = []
                current_frame_tracks = set()  # Track IDs trong frame hi·ªán t·∫°i

                for result in results:
                    annotated_frame = result.plot()

                    # L·∫•y th√¥ng tin detection
                    if result.boxes is not None and len(result.boxes) > 0:
                        for box in result.boxes:
                            class_id = int(box.cls[0])
                            class_name = model.names[class_id]
                            confidence = float(box.conf[0])

                            # L·∫•y track_id n·∫øu ƒëang tracking
                            if use_tracking and hasattr(box, 'id') and box.id is not None:
                                track_id = int(box.id[0])
                                current_frame_tracks.add(track_id)

                                # Ch·ªâ ƒë·∫øm n·∫øu ch∆∞a t·ª´ng ƒë·∫øm track_id n√†y
                                if track_id not in st.session_state.unique_objects:
                                    st.session_state.unique_objects.add(track_id)
                                    st.session_state.detection_count[class_name] += 1
                                    st.session_state.total_detections += 1

                                    # L∆∞u th√¥ng tin tracked object
                                    st.session_state.tracked_objects[track_id] = {
                                        'class': class_name,
                                        'first_seen': datetime.now(),
                                        'last_seen': datetime.now(),
                                        'counted': True
                                    }

                                    # Th√™m v√†o l·ªãch s·ª≠
                                    st.session_state.detection_history.append({
                                        'Th·ªùi gian': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                        'Lo·∫°i v≈© kh√≠': class_name,
                                        'ƒê·ªô tin c·∫≠y': f"{confidence:.2%}",
                                        'Track ID': track_id
                                    })

                                    # Th√™m c·∫£nh b√°o
                                    st.session_state.alert_log.append({
                                        'time': datetime.now().strftime("%H:%M:%S"),
                                        'weapon': class_name,
                                        'confidence': confidence,
                                        'track_id': track_id
                                    })
                                else:
                                    # C·∫≠p nh·∫≠t last_seen
                                    if track_id in st.session_state.tracked_objects:
                                        st.session_state.tracked_objects[track_id]['last_seen'] = datetime.now()

                            else:
                                # Kh√¥ng tracking - ƒë·∫øm m·ªói detection (nh∆∞ c≈©)
                                detected_objects.append({
                                    'class': class_name,
                                    'confidence': confidence,
                                    'time': datetime.now().strftime("%H:%M:%S")
                                })

                                st.session_state.detection_count[class_name] += 1
                                st.session_state.total_detections += 1

                                st.session_state.detection_history.append({
                                    'Th·ªùi gian': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                    'Lo·∫°i v≈© kh√≠': class_name,
                                    'ƒê·ªô tin c·∫≠y': f"{confidence:.2%}"
                                })

                                st.session_state.alert_log.append({
                                    'time': datetime.now().strftime("%H:%M:%S"),
                                    'weapon': class_name,
                                    'confidence': confidence
                                })

                    # Hi·ªÉn th·ªã video
                    frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                    video_placeholder.image(frame_rgb, channels="RGB", width="stretch")

                # X√≥a c√°c tracked objects c≈© (qu√° th·ªùi gian persist)
                if use_tracking:
                    current_time_dt = datetime.now()
                    expired_tracks = []
                    for track_id, info in st.session_state.tracked_objects.items():
                        time_diff = (current_time_dt - info['last_seen']).total_seconds()
                        if time_diff > tracking_persist:
                            expired_tracks.append(track_id)

                    for track_id in expired_tracks:
                        del st.session_state.tracked_objects[track_id]
                        st.session_state.unique_objects.discard(track_id)

                # C·∫≠p nh·∫≠t metrics
                total_metric.metric("T·ªïng ph√°t hi·ªán", st.session_state.total_detections)
                unique_metric.metric("S·ªë lo·∫°i v≈© kh√≠", len(st.session_state.detection_count))

                # C·∫≠p nh·∫≠t b·∫£ng ƒë·∫øm
                if st.session_state.detection_count:
                    count_df = pd.DataFrame([
                        {'Lo·∫°i v≈© kh√≠': k, 'S·ªë l·∫ßn xu·∫•t hi·ªán': v}
                        for k, v in st.session_state.detection_count.items()
                    ]).sort_values('S·ªë l·∫ßn xu·∫•t hi·ªán', ascending=False)
                    count_table.dataframe(count_df, width="stretch", hide_index=True)

                # Hi·ªÉn th·ªã c·∫£nh b√°o
                if st.session_state.alert_log:
                    recent_alerts = st.session_state.alert_log[-5:]  # 5 c·∫£nh b√°o g·∫ßn nh·∫•t
                    alert_text = ""
                    for alert in reversed(recent_alerts):
                        alert_text += f"üö® **{alert['time']}** - Ph√°t hi·ªán **{alert['weapon']}** ({alert['confidence']:.2%})\n\n"
                    alert_placeholder.markdown(f'<div class="alert-box">{alert_text}</div>', unsafe_allow_html=True)

                # Hi·ªÉn th·ªã l·ªãch s·ª≠
                if st.session_state.detection_history:
                    history_df = pd.DataFrame(st.session_state.detection_history[-20:])  # 20 ph√°t hi·ªán g·∫ßn nh·∫•t
                    history_placeholder.dataframe(history_df, width="stretch", hide_index=True)

                frame_count += 1

                # Kh√¥ng c·∫ßn sleep n·ªØa v√¨ ƒë√£ c√≥ frame_interval
                # time.sleep(0.01)

            cap.release()
    else:
        st.error("‚ùå Kh√¥ng th·ªÉ load model. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
        st.session_state.running = False
else:
    video_placeholder.info("üì∑ Nh·∫•n 'B·∫Øt ƒë·∫ßu' ƒë·ªÉ b·∫≠t camera v√† ph√°t hi·ªán v≈© kh√≠")

    # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë√£ c√≥ (n·∫øu c√≥)
    if st.session_state.total_detections > 0:
        total_metric.metric("T·ªïng ph√°t hi·ªán", st.session_state.total_detections)
        unique_metric.metric("S·ªë lo·∫°i v≈© kh√≠", len(st.session_state.detection_count))

        if st.session_state.detection_count:
            count_df = pd.DataFrame([
                {'Lo·∫°i v≈© kh√≠': k, 'S·ªë l·∫ßn xu·∫•t hi·ªán': v}
                for k, v in st.session_state.detection_count.items()
            ]).sort_values('S·ªë l·∫ßn xu·∫•t hi·ªán', ascending=False)
            count_table.dataframe(count_df, width="stretch", hide_index=True)

        if st.session_state.detection_history:
            history_df = pd.DataFrame(st.session_state.detection_history[-20:])
            history_placeholder.dataframe(history_df, width="stretch", hide_index=True)
